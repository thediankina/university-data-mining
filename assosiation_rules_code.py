# -*- coding: utf-8 -*-
"""Галиулина_ПоискАссоциативныхПравил.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ppa-lF2ChN5JGTDFITDCGgdl9EaGBZkm
"""

!pip install apyori

from apyori import apriori
import gzip
from datetime import datetime
import time
import matplotlib.pyplot as plt
import numpy as np

!wget http://fimi.uantwerpen.be/data/retail.dat.gz
!wget http://fimi.uantwerpen.be/data/accidents.dat.gz

def convert_gzip(filename, length):
  '''
  Convert from bytes to array(arrays) which are split by \n
  : param filename: string gzip archive name
  : param length: integer number of transactions
  :return:
  '''
  this_file = gzip.open(filename, "rb")
  file_content = list(this_file.read())
  a = []
  result = []
  for elem in file_content:
    if elem == 10:
      result.append(a)
      a = []
    else:
      a.append(elem)
  return result[:length]

def get_itemsets_and_supports(apriori_algorithm_result):
    '''
    Get frequent itemsets with their supports from apriori result
    : param apriori_algorithm_result: list of itemsets, supports and etc
    :return:
    '''
    result_list = []
    for record in apriori_algorithm_result:
      this_confidence = 0.0
      assosiation_rule = ''
      for stat in record.ordered_statistics:
          this_confidence = stat.confidence
          assosiation_rule = str(stat.items_base) + " -> " + str(stat.items_add)
      result_list.append((record.items, record.support, this_confidence, assosiation_rule))
    return result_list

def get_apriori_result(transactions, min_support, min_confidence, ordering_method):
  '''
  Run apriori algorithm
  : param transactions: array of array transactions
  : param min_support: real number of minimal support
  : param min_confidence: real number of minimal confidence
  : param ordering_method: ordering method for result itemset
  :return:
  '''
  result = list(apriori(transactions, min_support=min_support, min_confidence=min_confidence))
  frequent_itemsets_with_supports = get_itemsets_and_supports(result)
  if ordering_method == "descending_support":
    frequent_itemsets_with_supports.sort(key=lambda i: i[1])
  if ordering_method == "lexicographic":
    frequent_itemsets_with_supports.sort(key=lambda i: i[0])
  return frequent_itemsets_with_supports

transactions = [convert_gzip("retail.dat.gz", 3000), convert_gzip("accidents.dat.gz", 5000)]
min_support = np.arange(0.3, 0.8, 0.1)
min_confidence = np.arange(0.7, 0.9, 0.05)
ordering_method = ["descending_support", "lexicographic"]
print("number of transactions")
print("retail:    ", len(transactions[0]))
print("accidents: ", len(transactions[1]))
print("\nminimal support values: ", min_support)
print("minimal confidence values: ", min_confidence)

def get_execution_time(transactions, ordering_method, min_support=min_support, min_confidence=min_confidence):
  '''
  Measure execution time
  : param transactions: array of array transactions
  : param ordering_method: ordering method for result itemset
  : param min_support: real number of minimal support
  : param min_confidence: real number of minimal confidence
  :return:
  '''
  execution_time = []
  number_of_itemsets = []
  for min_confidence_value in min_confidence:
    start_time = datetime.now()
    frequent_itemsets_with_supports = get_apriori_result(transactions, min_support[0], min_confidence_value, ordering_method)
    number_of_itemsets.append(len(frequent_itemsets_with_supports))
    execute_interval = datetime.now() - start_time
    execution_time.append(execute_interval)
    print(frequent_itemsets_with_supports)
  return execution_time, number_of_itemsets

execution_times = []
execution_times.append(get_execution_time(transactions[0], ordering_method[0]))
execution_times.append(get_execution_time(transactions[1], ordering_method[0]))

def convert_seconds(times):
  '''
  Convert seconds in execution time to microseconds
  : param times: array of datetime.timedelta
  return:
  '''
  y = []
  for t in times:
    if t.seconds:
      y.append(int(t.seconds)*1000 + int(t.microseconds))
    else:
      y.append(int(t.microseconds))
  return y

x1 = min_confidence + 0.007
x2 = min_confidence - 0.007
y1 = convert_seconds(execution_times[0][0])
y2 = convert_seconds(execution_times[1][0])

plt.title('Speed')
plt.xlabel('minimal confidence')
plt.ylabel('microseconds')
plt.bar(x1, y1, label = 'retail', width = 0.015)
plt.bar(x2, y2, label = 'accidents', width = 0.015)
plt.legend(loc = 'upper left')
plt.show()

y1 = execution_times[0][1]
y2 = execution_times[1][1]

plt.title('Itemsets')
plt.xlabel('minimal confidence')
plt.ylabel('count')
plt.ylim(1900, 2050)
plt.bar(x1, y1, label = 'retail', width = 0.015)
plt.bar(x2, y2, label = 'accidents', width = 0.015)
plt.legend(loc = 'upper left')
plt.show()
